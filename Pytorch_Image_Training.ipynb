{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/NXOdz6nffombOt12k0lN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeulboGom/J_Automation_Project/blob/KH/Pytorch_Image_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 분할을 위한 폴더 생성"
      ],
      "metadata": {
        "id": "E-aR7Rx7p4zI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r3qfR8BnacCt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zd5B_aR0nmqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4340312-6acf-422e-b99d-5b5c79cb54fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_dataset_dir = '/content/drive/MyDrive/pytorch/dataset'\n",
        "classes_list = os.listdir(original_dataset_dir)"
      ],
      "metadata": {
        "id": "vQf35-49eWSl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/pytorch/splitted'\n",
        "os.mkdir(base_dir)"
      ],
      "metadata": {
        "id": "czqxjEh6lT7W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)"
      ],
      "metadata": {
        "id": "4Bqrv1PzlT9e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for clss in classes_list:\n",
        "  os.mkdir(os.path.join(train_dir, clss))\n",
        "  os.mkdir(os.path.join(validation_dir, clss))\n",
        "  os.mkdir(os.path.join(test_dir, clss))"
      ],
      "metadata": {
        "id": "lKjBSxdQliJ1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 분할과 클래스별 데이터 수 확인"
      ],
      "metadata": {
        "id": "7FyAuqLJp-gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "for clss in classes_list:\n",
        "  path = os.path.join(original_dataset_dir, clss)\n",
        "  fnames = os.listdir(path)\n",
        "\n",
        "  train_size = math.floor(len(fnames) * 0.6)\n",
        "  validation_size = math.floor(len(fnames) * 0.2)\n",
        "  test_size = math.floor(len(fnames) * 0.2)\n",
        "\n",
        "  train_fnames = fnames[:train_size]\n",
        "  print('Train size(',clss,'): ', len(train_fnames))\n",
        "  for fname in train_fnames:\n",
        "    src = os.path.join(path, fname)\n",
        "    dst = os.path.join(os.path.join(train_dir, clss), fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "  validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
        "  print('Validation size(',clss,'): ', len(validation_fnames))\n",
        "  for fname in validation_fnames:\n",
        "    src = os.path.join(path, fname)\n",
        "    dst = os.path.join(os.path.join(validation_dir, clss), fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "  test_fnames = fnames[(train_size + validation_size):(validation_size + train_size + test_size)]\n",
        "\n",
        "  print('Test size(',clss,'): ', len(test_fnames))\n",
        "  for fname in test_fnames:\n",
        "    src = os.path.join(path, fname)\n",
        "    dst = os.path.join(os.path.join(test_dir, clss), fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n"
      ],
      "metadata": {
        "id": "JBtWIHv-liMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01be1ec9-bce2-4605-b06e-1a79da87c09b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size( normal_up ):  44\n",
            "Validation size( normal_up ):  14\n",
            "Test size( normal_up ):  14\n",
            "Train size( abnormal_up ):  30\n",
            "Validation size( abnormal_up ):  10\n",
            "Test size( abnormal_up ):  10\n",
            "Train size( normal_down ):  29\n",
            "Validation size( normal_down ):  9\n",
            "Test size( normal_down ):  9\n",
            "Train size( abnormal_down ):  21\n",
            "Validation size( abnormal_down ):  7\n",
            "Test size( abnormal_down ):  7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "베이스라인 모델학습을 위한 준비"
      ],
      "metadata": {
        "id": "hdEkW0f5um1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "EPOCH = 30\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "transform_base = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])\n",
        "\n",
        "train_dataset = ImageFolder(root='/content/drive/MyDrive/pytorch/splitted/train', transform=transform_base)\n",
        "val_dataset = ImageFolder(root='/content/drive/MyDrive/pytorch/splitted/val', transform=transform_base)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n"
      ],
      "metadata": {
        "id": "RML5wVVjliOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86bd95f0-57e5-48a9-ccae-6e820464622b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "베이스라인 모델 설계\n",
        "\n"
      ],
      "metadata": {
        "id": "y6FFzPtYx8Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "\n",
        "    self.fc1 = nn.Linear(4096, 512)\n",
        "    self.fc2 = nn.Linear(512, 33)\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = F.dropout(x, p=0.25, training=self.training)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = F.dropout(x, p=0.25, training=self.training)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = F.dropout(x, p=0.25, training=self.training)\n",
        "\n",
        "    x = x.view(-1, 4096)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "model_base = Net().to(DEVICE)\n",
        "optimizer = optim.Adam(model_base.parameters(), lr=0.001)\n",
        "\n"
      ],
      "metadata": {
        "id": "3_DR3HOPumCg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습을 위한 함수"
      ],
      "metadata": {
        "id": "ea8GmJIV17Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.cross_entropy(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "WoYXI3ykumE3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 평가를 위한 함수"
      ],
      "metadata": {
        "id": "EaHBWOmL6nnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "      output = model(data)\n",
        "\n",
        "      test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "      pred = output.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "  return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "55yvPFz66QYS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습 실행하기"
      ],
      "metadata": {
        "id": "enZybAzu7Wyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "def train_baseline(model, train_loader, val_loader, optimizer, num_epochs = 30):\n",
        "  best_acc = 0.0\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "    since = time.time()\n",
        "    train(model, train_loader, optimizer)\n",
        "    train_loss, train_acc = evaluate(model, train_loader)\n",
        "    val_loss, val_acc = evaluate(model, val_loader)\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = val_acc\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('-------------- epoch {} ----------------'.format(epoch))\n",
        "\n",
        "    print('train Loss: {:.4f}, Accuracy: {:.2f}%' .format(train_loss, train_acc))\n",
        "\n",
        "    print('val Loss: {:.4f}, Accuracy: {:.2f}%' .format(val_loss, val_acc))\n",
        "\n",
        "    print('Completed in {:.0f}m {:.0f}s' .format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model\n",
        "\n",
        "base = train_baseline(model_base, train_loader, val_loader, optimizer, EPOCH)\n",
        "\n",
        "torch.save(base,'baseline.pt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xAp75Ly6Qb8",
        "outputId": "c933900e-fdb8-4801-ab55-dc525c47bdcf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- epoch 1 ----------------\n",
            "train Loss: 3.0775, Accuracy: 35.48%\n",
            "val Loss: 3.0797, Accuracy: 35.00%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 2 ----------------\n",
            "train Loss: 2.1041, Accuracy: 35.48%\n",
            "val Loss: 2.1148, Accuracy: 35.00%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 3 ----------------\n",
            "train Loss: 1.1523, Accuracy: 54.84%\n",
            "val Loss: 1.1766, Accuracy: 52.50%\n",
            "Completed in 0m 9s\n",
            "-------------- epoch 4 ----------------\n",
            "train Loss: 1.0153, Accuracy: 47.58%\n",
            "val Loss: 1.0625, Accuracy: 47.50%\n",
            "Completed in 0m 12s\n",
            "-------------- epoch 5 ----------------\n",
            "train Loss: 0.7636, Accuracy: 74.19%\n",
            "val Loss: 0.7987, Accuracy: 57.50%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 6 ----------------\n",
            "train Loss: 0.7336, Accuracy: 58.87%\n",
            "val Loss: 0.7814, Accuracy: 57.50%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 7 ----------------\n",
            "train Loss: 0.6032, Accuracy: 69.35%\n",
            "val Loss: 0.6878, Accuracy: 67.50%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 8 ----------------\n",
            "train Loss: 0.6470, Accuracy: 56.45%\n",
            "val Loss: 0.8056, Accuracy: 52.50%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 9 ----------------\n",
            "train Loss: 0.5636, Accuracy: 68.55%\n",
            "val Loss: 0.7264, Accuracy: 55.00%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 10 ----------------\n",
            "train Loss: 0.4594, Accuracy: 83.06%\n",
            "val Loss: 0.5718, Accuracy: 67.50%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 11 ----------------\n",
            "train Loss: 0.5165, Accuracy: 76.61%\n",
            "val Loss: 0.6059, Accuracy: 72.50%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 12 ----------------\n",
            "train Loss: 0.4721, Accuracy: 81.45%\n",
            "val Loss: 0.5685, Accuracy: 77.50%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 13 ----------------\n",
            "train Loss: 0.3789, Accuracy: 83.06%\n",
            "val Loss: 0.5178, Accuracy: 67.50%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 14 ----------------\n",
            "train Loss: 0.3656, Accuracy: 84.68%\n",
            "val Loss: 0.5926, Accuracy: 62.50%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 15 ----------------\n",
            "train Loss: 0.3839, Accuracy: 83.87%\n",
            "val Loss: 0.6818, Accuracy: 65.00%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 16 ----------------\n",
            "train Loss: 0.3540, Accuracy: 91.13%\n",
            "val Loss: 0.6674, Accuracy: 70.00%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 17 ----------------\n",
            "train Loss: 0.3022, Accuracy: 95.16%\n",
            "val Loss: 0.5928, Accuracy: 75.00%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 18 ----------------\n",
            "train Loss: 0.2609, Accuracy: 91.94%\n",
            "val Loss: 0.4981, Accuracy: 75.00%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 19 ----------------\n",
            "train Loss: 0.2419, Accuracy: 91.13%\n",
            "val Loss: 0.4340, Accuracy: 77.50%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 20 ----------------\n",
            "train Loss: 0.2270, Accuracy: 92.74%\n",
            "val Loss: 0.3913, Accuracy: 80.00%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 21 ----------------\n",
            "train Loss: 0.2005, Accuracy: 100.00%\n",
            "val Loss: 0.3629, Accuracy: 87.50%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 22 ----------------\n",
            "train Loss: 0.1695, Accuracy: 100.00%\n",
            "val Loss: 0.3626, Accuracy: 87.50%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 23 ----------------\n",
            "train Loss: 0.1393, Accuracy: 100.00%\n",
            "val Loss: 0.4032, Accuracy: 85.00%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 24 ----------------\n",
            "train Loss: 0.1173, Accuracy: 100.00%\n",
            "val Loss: 0.5010, Accuracy: 82.50%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 25 ----------------\n",
            "train Loss: 0.1000, Accuracy: 99.19%\n",
            "val Loss: 0.6104, Accuracy: 77.50%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 26 ----------------\n",
            "train Loss: 0.0838, Accuracy: 99.19%\n",
            "val Loss: 0.7260, Accuracy: 77.50%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 27 ----------------\n",
            "train Loss: 0.0687, Accuracy: 99.19%\n",
            "val Loss: 0.8179, Accuracy: 77.50%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 28 ----------------\n",
            "train Loss: 0.0546, Accuracy: 99.19%\n",
            "val Loss: 0.8529, Accuracy: 77.50%\n",
            "Completed in 0m 7s\n",
            "-------------- epoch 29 ----------------\n",
            "train Loss: 0.0370, Accuracy: 100.00%\n",
            "val Loss: 0.8338, Accuracy: 77.50%\n",
            "Completed in 0m 6s\n",
            "-------------- epoch 30 ----------------\n",
            "train Loss: 0.0257, Accuracy: 100.00%\n",
            "val Loss: 0.7563, Accuracy: 77.50%\n",
            "Completed in 0m 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning을 위한 준비"
      ],
      "metadata": {
        "id": "CMTk-GeY-Zmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize([64,64]),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomCrop(52),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize([64,64]),\n",
        "        transforms.RandomCrop(52),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "data_dir = '/content/drive/MyDrive/pytorch/splitted'\n",
        "image_datasets = {x: ImageFolder(root=os.path.join(data_dir, x), transform=data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "class_names = image_datasets['train'].classes\n"
      ],
      "metadata": {
        "id": "7ZMtRI2n6Qhb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Trained Model 불러오기"
      ],
      "metadata": {
        "id": "MyVsRjIFAjZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "num_ftrs = resnet.fc.in_features\n",
        "resnet.fc = nn.Linear(num_ftrs, 33)\n",
        "resnet = resnet.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=0.001)\n",
        "\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "5mKThJJTumHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf2069b-835a-4708-e85c-4b05b00eeb49"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 65.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Trained Model의 일부 Layer Freeze하기"
      ],
      "metadata": {
        "id": "_F8OF-HOA9rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ct = 0\n",
        "for child in resnet.children():\n",
        "  ct += 1\n",
        "  if ct < 6:\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False"
      ],
      "metadata": {
        "id": "jASqst6vAm9J"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning 모델 학습과 검증을 위한 함수"
      ],
      "metadata": {
        "id": "7eVu8Te5Bafv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_resnet(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print('-------------epoch {}-------------'.format(epoch+1))\n",
        "    since = time.time()\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      for inputs, labels in dataloaders[phase]:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "      if phase == 'train':\n",
        "        scheduler.step()\n",
        "        l_r = [x['lr'] for x in optimizer_ft.param_groups]\n",
        "        print('learning rate: ',l_r)\n",
        "\n",
        "      epoch_loss = running_loss/dataset_sizes[phase]\n",
        "      epoch_acc = running_corrects.double()/dataset_sizes[phase]\n",
        "\n",
        "      print('{} Loss: {:.4f} Acc: {:.4f}' .format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Completed in {:.0f}m {:.0f}s' .format(time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "VGVKEif_umKI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습 실행하기"
      ],
      "metadata": {
        "id": "3VfE4c8JDbBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet50 = train_resnet(resnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=EPOCH)\n",
        "\n",
        "torch.save(model_resnet50, 'resnet50.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9duDEYkLDaVy",
        "outputId": "aceafe91-5215-4c4a-f572-91e708b63057"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------epoch 1-------------\n",
            "learning rate:  [0.001]\n",
            "train Loss: 3.8433 Acc: 0.0000\n",
            "val Loss: 2.9192 Acc: 0.4750\n",
            "Completed in 0m 12s\n",
            "-------------epoch 2-------------\n",
            "learning rate:  [0.001]\n",
            "train Loss: 1.4996 Acc: 0.7581\n",
            "val Loss: 2.4704 Acc: 0.6750\n",
            "Completed in 0m 12s\n",
            "-------------epoch 3-------------\n",
            "learning rate:  [0.001]\n",
            "train Loss: 0.3939 Acc: 0.8548\n",
            "val Loss: 0.4268 Acc: 0.8000\n",
            "Completed in 0m 10s\n",
            "-------------epoch 4-------------\n",
            "learning rate:  [0.001]\n",
            "train Loss: 0.1396 Acc: 0.9516\n",
            "val Loss: 0.0535 Acc: 0.9750\n",
            "Completed in 0m 11s\n",
            "-------------epoch 5-------------\n",
            "learning rate:  [0.001]\n",
            "train Loss: 0.0843 Acc: 0.9677\n",
            "val Loss: 0.0508 Acc: 0.9750\n",
            "Completed in 0m 13s\n",
            "-------------epoch 6-------------\n",
            "learning rate:  [0.001]\n",
            "train Loss: 0.0035 Acc: 1.0000\n",
            "val Loss: 0.0235 Acc: 0.9750\n",
            "Completed in 0m 14s\n",
            "-------------epoch 7-------------\n",
            "learning rate:  [0.0001]\n",
            "train Loss: 0.0179 Acc: 0.9919\n",
            "val Loss: 5.6575 Acc: 0.6500\n",
            "Completed in 0m 13s\n",
            "-------------epoch 8-------------\n",
            "learning rate:  [0.0001]\n",
            "train Loss: 0.0018 Acc: 1.0000\n",
            "val Loss: 6.0753 Acc: 0.6500\n",
            "Completed in 0m 13s\n",
            "-------------epoch 9-------------\n",
            "learning rate:  [0.0001]\n",
            "train Loss: 0.0027 Acc: 1.0000\n",
            "val Loss: 4.9804 Acc: 0.6500\n",
            "Completed in 0m 12s\n",
            "-------------epoch 10-------------\n",
            "learning rate:  [0.0001]\n",
            "train Loss: 0.0022 Acc: 1.0000\n",
            "val Loss: 3.4400 Acc: 0.7000\n",
            "Completed in 0m 12s\n",
            "-------------epoch 11-------------\n",
            "learning rate:  [0.0001]\n",
            "train Loss: 0.0042 Acc: 1.0000\n",
            "val Loss: 3.0261 Acc: 0.7000\n",
            "Completed in 0m 14s\n",
            "-------------epoch 12-------------\n",
            "learning rate:  [0.0001]\n",
            "train Loss: 0.0079 Acc: 1.0000\n",
            "val Loss: 1.7879 Acc: 0.7000\n",
            "Completed in 0m 15s\n",
            "-------------epoch 13-------------\n",
            "learning rate:  [0.0001]\n",
            "train Loss: 0.0008 Acc: 1.0000\n",
            "val Loss: 1.1062 Acc: 0.8000\n",
            "Completed in 0m 14s\n",
            "-------------epoch 14-------------\n",
            "learning rate:  [1e-05]\n",
            "train Loss: 0.0005 Acc: 1.0000\n",
            "val Loss: 1.0862 Acc: 0.8500\n",
            "Completed in 0m 12s\n",
            "-------------epoch 15-------------\n",
            "learning rate:  [1e-05]\n",
            "train Loss: 0.0014 Acc: 1.0000\n",
            "val Loss: 0.8271 Acc: 0.8750\n",
            "Completed in 0m 12s\n",
            "-------------epoch 16-------------\n",
            "learning rate:  [1e-05]\n",
            "train Loss: 0.0008 Acc: 1.0000\n",
            "val Loss: 0.4563 Acc: 0.8500\n",
            "Completed in 0m 12s\n",
            "-------------epoch 17-------------\n",
            "learning rate:  [1e-05]\n",
            "train Loss: 0.0014 Acc: 1.0000\n",
            "val Loss: 0.1225 Acc: 0.9250\n",
            "Completed in 0m 12s\n",
            "-------------epoch 18-------------\n",
            "learning rate:  [1e-05]\n",
            "train Loss: 0.0005 Acc: 1.0000\n",
            "val Loss: 0.0690 Acc: 0.9500\n",
            "Completed in 0m 13s\n",
            "-------------epoch 19-------------\n",
            "learning rate:  [1e-05]\n",
            "train Loss: 0.0006 Acc: 1.0000\n",
            "val Loss: 0.2247 Acc: 0.9250\n",
            "Completed in 0m 13s\n",
            "-------------epoch 20-------------\n",
            "learning rate:  [1e-05]\n",
            "train Loss: 0.0005 Acc: 1.0000\n",
            "val Loss: 0.0939 Acc: 0.9750\n",
            "Completed in 0m 12s\n",
            "-------------epoch 21-------------\n",
            "learning rate:  [1.0000000000000002e-06]\n",
            "train Loss: 0.0003 Acc: 1.0000\n",
            "val Loss: 0.0676 Acc: 0.9750\n",
            "Completed in 0m 13s\n",
            "-------------epoch 22-------------\n",
            "learning rate:  [1.0000000000000002e-06]\n",
            "train Loss: 0.0007 Acc: 1.0000\n",
            "val Loss: 0.0041 Acc: 1.0000\n",
            "Completed in 0m 12s\n",
            "-------------epoch 23-------------\n",
            "learning rate:  [1.0000000000000002e-06]\n",
            "train Loss: 0.0004 Acc: 1.0000\n",
            "val Loss: 0.0874 Acc: 0.9500\n",
            "Completed in 0m 10s\n",
            "-------------epoch 24-------------\n",
            "learning rate:  [1.0000000000000002e-06]\n",
            "train Loss: 0.0006 Acc: 1.0000\n",
            "val Loss: 0.0090 Acc: 1.0000\n",
            "Completed in 0m 13s\n",
            "-------------epoch 25-------------\n",
            "learning rate:  [1.0000000000000002e-06]\n",
            "train Loss: 0.0009 Acc: 1.0000\n",
            "val Loss: 0.0055 Acc: 1.0000\n",
            "Completed in 0m 14s\n",
            "-------------epoch 26-------------\n",
            "learning rate:  [1.0000000000000002e-06]\n",
            "train Loss: 0.0005 Acc: 1.0000\n",
            "val Loss: 0.0051 Acc: 1.0000\n",
            "Completed in 0m 13s\n",
            "-------------epoch 27-------------\n",
            "learning rate:  [1.0000000000000002e-06]\n",
            "train Loss: 0.0012 Acc: 1.0000\n",
            "val Loss: 0.0230 Acc: 0.9750\n",
            "Completed in 0m 13s\n",
            "-------------epoch 28-------------\n",
            "learning rate:  [1.0000000000000002e-07]\n",
            "train Loss: 0.0004 Acc: 1.0000\n",
            "val Loss: 0.0417 Acc: 0.9750\n",
            "Completed in 0m 13s\n",
            "-------------epoch 29-------------\n",
            "learning rate:  [1.0000000000000002e-07]\n",
            "train Loss: 0.0017 Acc: 1.0000\n",
            "val Loss: 0.0292 Acc: 0.9750\n",
            "Completed in 0m 12s\n",
            "-------------epoch 30-------------\n",
            "learning rate:  [1.0000000000000002e-07]\n",
            "train Loss: 0.0003 Acc: 1.0000\n",
            "val Loss: 0.0349 Acc: 0.9750\n",
            "Completed in 0m 11s\n",
            "Best val Acc: 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "베이스라인 모델 평가를 위한 전처리"
      ],
      "metadata": {
        "id": "pFzN2V4wEC6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_base = transforms.Compose([transforms.Resize([64,64]), transforms.ToTensor()])\n",
        "\n",
        "test_base = ImageFolder(root='/content/drive/MyDrive/pytorch/splitted/test', transform=transform_base)\n",
        "\n",
        "test_loader_base = torch.utils.data.DataLoader(test_base, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
      ],
      "metadata": {
        "id": "yWflbkNvDaYU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning모델 평가를 위한 전처리"
      ],
      "metadata": {
        "id": "qnT5BxIcEHGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_resNet = transforms.Compose([\n",
        "    transforms.Resize([64,64]),\n",
        "    transforms.RandomCrop(52),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "test_resNet = ImageFolder(root='/content/drive/MyDrive/pytorch/splitted/test', transform=transform_resNet)\n",
        "\n",
        "test_loader_resNet = torch.utils.data.DataLoader(test_resNet, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
      ],
      "metadata": {
        "id": "5aj8rsNYDaa0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "베이스라인 모델 성능 평가하기"
      ],
      "metadata": {
        "id": "SXp4PALTEhbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline=torch.load('baseline.pt')\n",
        "baseline.eval()\n",
        "test_loss, test_accuracy = evaluate(baseline, test_loader_base)\n",
        "\n",
        "print('baseline test acc: ', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhBoS-MoEk_a",
        "outputId": "7cf782f0-b2bc-4068-a8e9-f9616ebfca54"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "baseline test acc:  92.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning 모델 성능 평가하기"
      ],
      "metadata": {
        "id": "md0D2gypEvSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50=torch.load('resnet50.pt')\n",
        "resnet50.eval()\n",
        "test_loss, test_accuracy = evaluate(resnet50, test_loader_resNet)\n",
        "\n",
        "print('ResNet test acc: ', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYYf5cpcDad5",
        "outputId": "205a34c6-4f22-449c-c9ba-1dce2fcb356f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet test acc:  100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "# 이미지 경로를 입력받아 가장 비슷한 클래스를 출력하는 함수\n",
        "def predict_image_class(image_path, model):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize([64, 64]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_image = transform(image).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_image)\n",
        "        _, predicted_idx = torch.max(output, 1)\n",
        "\n",
        "    # 클래스 라벨\n",
        "    classes = ['abnormal_down', 'abnormal_up', 'normal_down', 'normal_up']\n",
        "\n",
        "    # 결과 출력\n",
        "    print(\"Predicted class: {}\".format(classes[predicted_idx.item()]))\n",
        "    print(\"Confidence: {:.2f}%\".format(F.softmax(output, dim=1)[0][predicted_idx.item()] * 100))\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "# 폴더 내의 모든 이미지 파일들을 가져와서 리스트에 추가\n",
        "folder_path = '/content/drive/MyDrive/all/'\n",
        "image_paths.extend(glob.glob(folder_path + '*.png'))\n",
        "\n",
        "# 'base' 모델로 이미지 분류 결과 출력\n",
        "for image_path in image_paths:\n",
        "    print(\"Image form base:\", image_path)\n",
        "    predict_image_class(image_path, base)\n",
        "    print()\n",
        "\n",
        "# 'resnet50' 모델로 이미지 분류 결과 출력\n",
        "for image_path in image_paths:\n",
        "    print(\"Image from resnet:\", image_path)\n",
        "    predict_image_class(image_path, resnet50)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMdaUWqilcmb",
        "outputId": "e6006c79-6e67-4c88-9890-8ef398ab45a1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image form base: /content/drive/MyDrive/all/abnormal_(7).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.47%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(5).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.84%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(16).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.97%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(8).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.89%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(14).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(18).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 91.86%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(4).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 95.15%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(3).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.96%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(23).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.95%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(24).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.11%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(17).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.73%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(1).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(9).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.00%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(26).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.97%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(22).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(11).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.73%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(25).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(15).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.02%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(21).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(13).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 98.68%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(19).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 98.68%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(12).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 91.77%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(20).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.90%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(6).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 96.11%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(10).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 92.62%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(2).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.15%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(27).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(38).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(28).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 90.24%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(47).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 88.82%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(44).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(49).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 91.68%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(31).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 96.01%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(40).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.74%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(28).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 83.78%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(36).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(41).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 92.37%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(50).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 98.79%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(33).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 92.75%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(33).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 97.99%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(43).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.90%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(31).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.97%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(46).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(37).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.11%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(45).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.31%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(29).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 85.98%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(35).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.90%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(32).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 92.24%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(30).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 60.85%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(42).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 98.73%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(34).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 98.71%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(48).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.73%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(32).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.05%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(29).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.81%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(30).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 99.73%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/abnormal_(39).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 89.31%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(35).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.79%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(52).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 80.91%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(41).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 72.65%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(44).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 86.45%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(50).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.25%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(55).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 84.03%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(40).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 91.67%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(45).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 88.35%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(54).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 71.92%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(43).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 97.42%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(49).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 98.71%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(57).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 53.84%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(53).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 86.43%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(48).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.64%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(63).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 90.17%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(60).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 76.87%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(42).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 95.55%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(47).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 88.02%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(38).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 72.69%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(59).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 81.38%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(61).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 84.49%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(46).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 74.52%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(51).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 98.34%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(58).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 74.14%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(62).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 76.04%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(39).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 92.93%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(34).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.94%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(37).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 85.58%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(56).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 91.83%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(36).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 80.70%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(11).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.03%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(12).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 98.32%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(72).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 55.17%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(16).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 77.20%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(65).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 85.67%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(4).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 96.88%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(8).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 91.82%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(68).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 76.41%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(1).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.73%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(14).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.84%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(66).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.70%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(64).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.41%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(2).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 98.85%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(7).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.92%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(6).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 62.74%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(18).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 86.59%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(3).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 84.62%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(74).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.59%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(67).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.25%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(5).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 68.98%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(73).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 98.84%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(10).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 67.58%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(13).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 89.82%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(70).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 74.64%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(15).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 81.35%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(75).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 94.86%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(71).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 90.12%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(9).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 85.19%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(17).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 88.62%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(69).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 86.61%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(25).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.11%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(27).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.55%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(19).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.28%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(22).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 97.44%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(21).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.87%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(23).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 72.70%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(26).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 94.16%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(20).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 97.36%\n",
            "\n",
            "Image form base: /content/drive/MyDrive/all/normal_(24).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 92.17%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(7).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(5).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(16).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(8).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(14).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(18).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(4).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(3).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(23).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(24).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(17).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(1).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(9).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(26).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(22).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(11).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(25).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(15).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(21).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(13).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(19).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(12).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(20).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(6).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(10).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(2).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(27).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(38).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(28).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(47).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(44).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(49).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(31).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 95.19%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(40).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(28).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(36).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(41).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(50).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(33).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(33).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.94%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(43).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(31).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(46).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(37).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(45).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(29).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.83%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(35).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(32).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(30).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 95.62%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(42).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(34).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(48).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(32).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(29).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(30).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/abnormal_(39).png\n",
            "Predicted class: abnormal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(35).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.75%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(52).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(41).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(44).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(50).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(55).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.92%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(40).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(45).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 97.04%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(54).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.97%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(43).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.76%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(49).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.95%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(57).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(53).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(48).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(63).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.92%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(60).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(42).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(47).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 97.43%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(38).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(59).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 98.89%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(61).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.94%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(46).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 91.54%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(51).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 98.56%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(58).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(62).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.95%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(39).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.57%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(34).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.97%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(37).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.49%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(56).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.96%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(36).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(11).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.81%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(12).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(72).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(16).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.95%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(65).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.96%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(4).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(8).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.94%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(68).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(1).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(14).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(66).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(64).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(2).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.88%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(7).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 98.08%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(6).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 48.28%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(18).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.90%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(3).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.85%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(74).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(67).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 97.31%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(5).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.97%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(73).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(10).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(13).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 100.00%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(70).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(15).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.92%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(75).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.95%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(71).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(9).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.88%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(17).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.97%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(69).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(25).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(27).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(19).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.98%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(22).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.95%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(21).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.99%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(23).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 98.41%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(26).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.87%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(20).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.81%\n",
            "\n",
            "Image from resnet: /content/drive/MyDrive/all/normal_(24).png\n",
            "Predicted class: normal_up\n",
            "Confidence: 99.37%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}